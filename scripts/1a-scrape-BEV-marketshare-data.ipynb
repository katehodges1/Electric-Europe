{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape country level data on EV market shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import StringIO\n",
    "import os\n",
    "import time\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define filepaths\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"config.ini\")\n",
    "\n",
    "# access values\n",
    "raw_path = Path(config[\"default\"][\"raw_path\"])\n",
    "interim_path = Path(config[\"default\"][\"interim_path\"])\n",
    "processed_path = Path(config[\"default\"][\"processed_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define target countries for scraping\n",
    "target_countries = [\n",
    "    \"Austria\",\"Belgium\",\"Bulgaria\",\"Croatia\",\"Cyprus\",\"Czech Republic\",\"Denmark\",\n",
    "    \"Estonia\",\"Finland\",\"France\",\"Germany\",\"Greece\",\"Hungary\",\"Iceland\",\"Ireland\",\n",
    "    \"Italy\",\"Latvia\",\"Liechtenstein\",\"Lithuania\",\"Luxembourg\",\"Malta\",\"Netherlands\",\n",
    "    \"Norway\",\"Poland\",\"Portugal\",\"Romania\",\"Slovakia\",\"Slovenia\",\"Spain\",\"Sweden\",\n",
    "    \"Switzerland\",\"Turkey\",\"United Kingdom\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Scraper function to fetch market share data for each country, logging any failed requests (due to too many requests) for retry\n",
    "* Save scraped data as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(target_countries, output_csv=interim_path/\"bev_market_share_data.csv\", failed_csv=interim_path/\"failed_countries.csv\", delay_range=(4,10)):\n",
    "    \"\"\"\n",
    "    Scrape BEV/PHEV yearly market share data from country pages from the European Alternative Fuels Observatory.\n",
    "\n",
    "    Args: \n",
    "        countries (list of str): List of target country names to fetch data for\n",
    "        output_csv (str): File path to save successfully scraped data\n",
    "        failed_csv (str): File path to store list of countries failed to fetch\n",
    "        delay_range (tuple): Min & max seconds to wait between requests (randomised to reduce risk of being rate limited)\n",
    "\n",
    "    Returns: \n",
    "        list: Countries that failed to scrape\n",
    "    \"\"\"\n",
    "\n",
    "    # create list to initially store data as its scraped\n",
    "    all_data = []\n",
    "\n",
    "    # in case of encountering timeout error, store failed countries to retry later\n",
    "    failed_countries = []\n",
    "\n",
    "    # define scraper loop\n",
    "    for country in target_countries:\n",
    "        slug = country.lower().replace(\" \", \"-\")\n",
    "        url = f\"https://alternative-fuels-observatory.ec.europa.eu/sites/default/files/csv/{slug}/market_share_new_registrations_m1.csv\"\n",
    "        \n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "        response = requests.get(url, headers=headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "        # read csv as pandas df directly from memory\n",
    "            df = pd.read_csv(StringIO(response.text))\n",
    "            print(f'Successfully loaded CSV for {country}')\n",
    "\n",
    "            df_clean = df[['YEAR', 'BEV', 'PHEV']].copy()\n",
    "            df_clean['Country'] = country\n",
    "            df_clean['BEV+PHEV'] = df_clean['BEV'] + df_clean['PHEV']\n",
    "            all_data.append(df_clean)\n",
    "        else:\n",
    "            print(f\"Failed for {country} ({response.status_code})\")\n",
    "            failed_countries.append(country)\n",
    "\n",
    "        # randomise delays to reduce risk of 429 error rate limiting\n",
    "        time.sleep(random.uniform(*delay_range)) # unpack tuple\n",
    "\n",
    "    # if any countries were scraped successfully...\n",
    "    if all_data:\n",
    "        final_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "        # if file already exists, append without header\n",
    "        try:\n",
    "            final_df.to_csv(output_csv, mode=\"a\", index = False, header=not os.path.exists(output_csv))\n",
    "        except:\n",
    "            final_df.to_csv(output_csv, index=False)\n",
    "\n",
    "        num_countries = final_df['Country'].nunique() # count how many countries data successfully scraped for\n",
    "        print(f\"Saved successfully scraped data for {num_countries} countries. \") # success message\n",
    "\n",
    "    # if anything was stored in failed countries...\n",
    "    if failed_countries:\n",
    "        pd.Series(failed_countries, name='country').to_csv(\"failed_countries.csv\", index=False)\n",
    "        print(f\"Saved {len(failed_countries)} to '{failed_csv}'.\")\n",
    "\n",
    "    else:\n",
    "        print(\"All countries fetched successfully.\")\n",
    "    return failed_countries\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop scraper until all countries fetched successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1: scraping 33 countries\n",
      "Successfully loaded CSV for Austria\n",
      "Successfully loaded CSV for Belgium\n",
      "Successfully loaded CSV for Bulgaria\n",
      "Successfully loaded CSV for Croatia\n",
      "Successfully loaded CSV for Cyprus\n",
      "Successfully loaded CSV for Czech Republic\n",
      "Successfully loaded CSV for Denmark\n",
      "Successfully loaded CSV for Estonia\n",
      "Successfully loaded CSV for Finland\n",
      "Successfully loaded CSV for France\n",
      "Successfully loaded CSV for Germany\n",
      "Successfully loaded CSV for Greece\n",
      "Successfully loaded CSV for Hungary\n",
      "Successfully loaded CSV for Iceland\n",
      "Successfully loaded CSV for Ireland\n",
      "Successfully loaded CSV for Italy\n",
      "Successfully loaded CSV for Latvia\n",
      "Successfully loaded CSV for Liechtenstein\n",
      "Successfully loaded CSV for Lithuania\n",
      "Successfully loaded CSV for Luxembourg\n",
      "Successfully loaded CSV for Malta\n",
      "Successfully loaded CSV for Netherlands\n",
      "Successfully loaded CSV for Norway\n",
      "Successfully loaded CSV for Poland\n",
      "Successfully loaded CSV for Portugal\n",
      "Successfully loaded CSV for Romania\n",
      "Successfully loaded CSV for Slovakia\n",
      "Successfully loaded CSV for Slovenia\n",
      "Successfully loaded CSV for Spain\n",
      "Successfully loaded CSV for Sweden\n",
      "Successfully loaded CSV for Switzerland\n",
      "Successfully loaded CSV for Turkey\n",
      "Successfully loaded CSV for United Kingdom\n",
      "Saved successfully scraped data for 33 countries. \n",
      "All countries fetched successfully.\n",
      "All countries successfully scraped\n"
     ]
    }
   ],
   "source": [
    "# initially assign entire target countries list as target 'to fetch'\n",
    "to_fetch = target_countries\n",
    "attempt = 1\n",
    "\n",
    "while to_fetch:\n",
    "    print(f\"Attempt {attempt}: scraping {len(to_fetch)} countries\")\n",
    "    # assign failed countries to list\n",
    "    failed = fetch_data(to_fetch, failed_csv=f\"failed_attempt{attempt}.csv\") \n",
    "\n",
    "    if not failed:\n",
    "        print(\"All countries successfully scraped\")\n",
    "        break\n",
    "    \n",
    "    # update 'to fetch' list with remaining failed countries\n",
    "    to_fetch = failed \n",
    "    attempt += 1\n",
    "\n",
    "    time.sleep(60) # wait 1 minute before retry"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envGEOG0178",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
