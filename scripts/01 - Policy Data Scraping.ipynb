{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Unstructured Policy Data\n",
    "From European Alternative Fuels Agency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml in /opt/anaconda3/envs/envGEOG0178/lib/python3.12/site-packages (6.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyyaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyyaml\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyyaml'"
     ]
    }
   ],
   "source": [
    "import pyyaml\n",
    "from pathlib import Path\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import json\n",
    "from urllib.parse import urljoin\n",
    "from urllib.robotparser import RobotFileParser\n",
    "\n",
    "import requests # for making HTTP requests to web pages\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "from bs4 import BeautifulSoup # enables HTML parsing\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingSectionHeaderError",
     "evalue": "File contains no section headers.\nfile: '/Users/katehodges/Desktop/Applications/Portfolio/Electric-Europe/scripts/config.yml', line: 1\n'default: \\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingSectionHeaderError\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m config_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/katehodges/Desktop/Applications/Portfolio/Electric-Europe/scripts/config.yml\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m config \u001b[38;5;241m=\u001b[39m configparser\u001b[38;5;241m.\u001b[39mConfigParser()\n\u001b[0;32m----> 3\u001b[0m \u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/envGEOG0178/lib/python3.12/configparser.py:684\u001b[0m, in \u001b[0;36mRawConfigParser.read\u001b[0;34m(self, filenames, encoding)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    683\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, encoding\u001b[38;5;241m=\u001b[39mencoding) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m--> 684\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/envGEOG0178/lib/python3.12/configparser.py:1064\u001b[0m, in \u001b[0;36mRawConfigParser._read\u001b[0;34m(self, fp, fpname)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# no section header in the file?\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m cursect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1064\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MissingSectionHeaderError(fpname, lineno, line)\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;66;03m# an option line?\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1067\u001b[0m     mo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optcre\u001b[38;5;241m.\u001b[39mmatch(value)\n",
      "\u001b[0;31mMissingSectionHeaderError\u001b[0m: File contains no section headers.\nfile: '/Users/katehodges/Desktop/Applications/Portfolio/Electric-Europe/scripts/config.yml', line: 1\n'default: \\n'"
     ]
    }
   ],
   "source": [
    "config_file = \"/Users/katehodges/Desktop/Applications/Portfolio/Electric-Europe/scripts/config.yml\"\n",
    "config = configparser.ConfigParser()\n",
    "config.read(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define target countries for scraping\n",
    "target_countries = [\n",
    "    \"Austria\",\"Belgium\",\"Bulgaria\",\"Croatia\",\"Cyprus\",\"Czech Republic\",\"Denmark\",\n",
    "    \"Estonia\",\"Finland\",\"France\",\"Germany\",\"Greece\",\"Hungary\",\"Iceland\",\"Ireland\",\n",
    "    \"Italy\",\"Latvia\",\"Liechtenstein\",\"Lithuania\",\"Luxembourg\",\"Malta\",\"Netherlands\",\n",
    "    \"Norway\",\"Poland\",\"Portugal\",\"Romania\",\"Slovakia\",\"Slovenia\",\"Spain\",\"Sweden\",\n",
    "    \"Switzerland\",\"Turkey\",\"United Kingdom\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loop through country list to get URLs for each country's policy page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/austria/incentives-legislations', 'https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/belgium/incentives-legislations', 'https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/bulgaria/incentives-legislations', 'https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/croatia/incentives-legislations', 'https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/cyprus/incentives-legislations', 'https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/czech-republic/incentives-legislations', 'https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/denmark/incentives-legislations', 'https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/estonia/incentives-legislations', 'https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/finland/incentives-legislations', 'https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/france/incentives-legislations', 'https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/germany/incentives-legislations', 'https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/greece/incentives-legislations', 'https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/hungary/incentives-legislations', 'https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/iceland/incentives-legislations', 'https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/ireland/incentives-legislations', 'https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/italy/incentives-legislations', 'https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/latvia/incentives-legislations', 'https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/liechtenstein/incentives-legislations', 'https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/lithuania/incentives-legislations', 'https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/luxembourg/incentives-legislations', 'https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/malta/incentives-legislations', 'https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/netherlands/incentives-legislations', 'https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/norway/incentives-legislations', 'https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/poland/incentives-legislations', 'https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/portugal/incentives-legislations', 'https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/romania/incentives-legislations', 'https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/slovakia/incentives-legislations', 'https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/slovenia/incentives-legislations', 'https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/spain/incentives-legislations', 'https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/sweden/incentives-legislations', 'https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/switzerland/incentives-legislations', 'https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/turkey/incentives-legislations', 'https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/united-kingdom/incentives-legislations']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define empty list to store\n",
    "country_urls = []\n",
    "\n",
    "for country in target_countries:\n",
    "    slug = country.lower().replace(\" \", \"-\") # all chars lower case, replace white space with url friendly dash\n",
    "    url = f\"https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/{slug}/incentives-legislations\"\n",
    "    country_urls.append(url)\n",
    "    #print(country, '->', url) #print to confirm\n",
    "\n",
    "print(country_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to scrape country policy text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_country_policy(url, country_name):\n",
    "    \n",
    "    # request page HTML\n",
    "    headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "    resp = requests.get(url, headers=headers, timeout=10)\n",
    "    # raise exception for exception to see what failed\n",
    "    resp.raise_for_status()\n",
    "\n",
    "    # parse HTML to BeautifulSoup DOM (tree like structure that enables searching & manipulation down the line)\n",
    "    soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "    # try to find main content area; fallback to body or whole soup if not found\n",
    "    main_section = soup.find('main') or soup.find(\"div\", {\"role\":\"main\"}) or soup.body or soup\n",
    "\n",
    "    # collect text segments from elements containing policy text\n",
    "        # headings: (h2/h3), paragraphs (p), list items (li)\n",
    "    segments = []\n",
    "\n",
    "    # find extract contents of main section by looping through elements\n",
    "    for elem in main_section.find_all([\"h2\", \"h3\", \"p\", \"li\"]):\n",
    "        text = elem.get_text(\" \", strip=True) # join 'children''with spaces and strip leading/ trailing whitespace\n",
    "        if text:\n",
    "            segments.append(text)\n",
    "    \n",
    "    # join segments into one large string (two spaces between segments to keep readability)\n",
    "    policy_text = \"  \".join(segments)\n",
    "\n",
    "    # return simple dict (later convert to pandas df)\n",
    "    return {\n",
    "        \"country\": country_name,\n",
    "        \"url\": url,\n",
    "        \"policy_text\": policy_text\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> TEST SCRAPE (single country): Austria https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/austria/incentives-legislations\n",
      "Scraped keys: dict_keys(['country', 'url', 'policy_text'])\n",
      "Country: Austria\n",
      "URL: https://alternative-fuels-observatory.ec.europa.eu/transport-mode/road/austria/incentives-legislations\n",
      "\n",
      "Policy text preview (first 700 chars):\n",
      "\n",
      "Summary  Target tracker  Vehicles and fleet  Infrastructure  Incentives & legislation  Useful information  Incentives and Legislation The incentives and legislations section is updated for 2025, published on 18th April 2025, representing the situation as of that date. Major changes of incentives and polices are updated on a rolling basis from that date onwards. Incentives and legislation that aim to increase uptake of alternative fuels vehicles and infrastructure. If you know of other national or local incentives that should be included in this section, please send us an email , or use the button on the right, and let us know. We review the proposed changes and implement the updates on a sho\n"
     ]
    }
   ],
   "source": [
    "### test scraper on single country\n",
    "\n",
    "try:\n",
    "    assert len(target_countries) == len(country_urls)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"Make sure 'target_countries' and 'country_urls' are defined and the same length\") from e\n",
    "\n",
    "# Pick one country to test (change index if you want another)\n",
    "test_idx = 0  # 0 => the first country in your lists\n",
    "test_country = target_countries[test_idx]\n",
    "test_url = country_urls[test_idx]\n",
    "\n",
    "print(\">>> TEST SCRAPE (single country):\", test_country, test_url)\n",
    "\n",
    "# Run the single-country scraper\n",
    "try:\n",
    "    test_result = scrape_country_policy(test_url, test_country)\n",
    "except Exception as e:\n",
    "    print(\"Error scraping the test page:\", e)\n",
    "else:\n",
    "    # Show what the function returned (data structure explanation)\n",
    "    # test_result is a Python dict: {'country': str, 'url': str, 'policy_text': str}\n",
    "    print(\"Scraped keys:\", test_result.keys())\n",
    "    print(\"Country:\", test_result[\"country\"])\n",
    "    print(\"URL:\", test_result[\"url\"])\n",
    "    # show a short preview of the scraped text:\n",
    "    print(\"\\nPolicy text preview (first 700 chars):\\n\")\n",
    "    print(test_result[\"policy_text\"][:700])  # preview first 700 chars\n",
    "    # Optionally store the single test result to disk for manual inspection\n",
    "    pd.DataFrame([test_result]).to_csv(\"raw_data/test_single_country.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# declare function that  returns policy text data as dictionary for every country - takes URL & country name as inputs\n",
    "def scrape_country_policy(url, country_name):\n",
    "    \"\"\"Scrape incentives/legislation text for one country.\"\"\"\n",
    "\n",
    "    # send HTTP request (storing result in requests.Response object)\n",
    "    response = requests.get(url)\n",
    "    # parses HTML string into parsable object\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    # attempt to find main section of site (which should contain policy text)\n",
    "    main_section = soup.find(\"main\")\n",
    "\n",
    "    # create empty list to collect strings\n",
    "    policy_text = []\n",
    "    \n",
    "    # pull headings, paragraphs, bullet points\n",
    "    for elem in main_section.find_all([\"h2\", \"h3\", \"p\", \"li\"]):\n",
    "        # strip leading/ trailing whitespace\n",
    "        text = elem.get_text(strip=True)\n",
    "        # append to policy text string just defined\n",
    "        if text:\n",
    "            policy_text.append(text)\n",
    "    \n",
    "    return {\n",
    "        \"country\": country_name,\n",
    "        \"policy_text\": \" \".join(policy_text)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define site URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "SITE_URL = \"https://alternative-fuels-observatory.ec.europa.eu\"\n",
    "base_url = SITE_URL + \"/transport-mode/road\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create loop to store country specific URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 country pages\n"
     ]
    }
   ],
   "source": [
    "# parse URLs as beautiful soup object\n",
    "res = requests.get(base_url)\n",
    "soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "# find all <a> tags with \"/road/{country}/incentives-legislations\"\n",
    "links = soup.find_all(\"a\", href=True)\n",
    "# empty list to store country specific URLs\n",
    "country_links = []\n",
    "# looping over country pages\n",
    "for a in links:\n",
    "    href = a[\"href\"]\n",
    "    if href.startswith(\"/transport-mode/road/\") and href.endswith(\"incentives-legislations\"):\n",
    "        country_name = a.get_text(strip=True)\n",
    "        full_url = SITE_URL + href\n",
    "        country_links.append((country_name, full_url))\n",
    "\n",
    "# print how many country pages found\n",
    "print(f\"Found {len(country_links)} country pages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over countries\n",
    "all_data = []\n",
    "for name, url in country_links:\n",
    "    try:\n",
    "        print(f\"Scraping {name}...\")\n",
    "        data = scrape_country_policy(url, name)\n",
    "        all_data.append(data)\n",
    "        time.sleep(1)  # polite delay\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed for {name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved to raw_data/policy_incentives.csv\n"
     ]
    }
   ],
   "source": [
    "# convert list of dictionaries to pandas dataframe\n",
    "df = pd.DataFrame(all_data)\n",
    "df.to_csv(\"raw_data/policy_incentives.csv\", index=False)\n",
    "\n",
    "print(\"✅ Saved to raw_data/policy_incentives.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envGEOG0178",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
